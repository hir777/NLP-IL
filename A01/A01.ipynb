{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### A01. Python Programming and Corpus"
      ],
      "metadata": {
        "id": "-I1zbijKsXMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeYGp6oMsRXs",
        "outputId": "7b24a7ad-aa16-4c92-c4f8-802c8d43c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. What is the difference between the following two lines? \n",
        "\n",
        "```\n",
        "sorted(set(w.lower() for w in text1))\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "sorted(w.lower() for w in set(text1))\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hynKlEZq36uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "sorted(set(w.lower() for w in text1))\n",
        "```\n",
        "\n",
        "This chunks of functions executes the following procedure.\n",
        "\n",
        "Step 1   Convert upper case to lower case in each word\n",
        "\n",
        "Step 2   Remove duplication of words\n",
        "\n",
        "Step 3   Sort the list of words\n",
        "\n",
        "Result   No duplicated words can be found because capitalized words is changed into lowercase words before overlapping of words is fixed.\n",
        "\n",
        "Let's say you have 'Apple' and 'apple' in a text. Both words are first converted both into 'apple' and then the duplication is removed. Therefore, you can find only one 'apple' in the resulting list. "
      ],
      "metadata": {
        "id": "N7cbyvttxz4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1_a = sorted(set(w.lower() for w in text1))\n",
        "\n",
        "# Check if there is duplicated words in the text1_a\n",
        "# If that's the case, the output of line 1 is larger than the one of line 2. \n",
        "print(len(text1_a))       # line 1\n",
        "print(len(set(text1_a)))  # line 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbiFi23OtUS2",
        "outputId": "2615dcd5-d471-4981-922b-ff682afb8d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17231\n",
            "17231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "sorted(w.lower() for w in set(text1))\n",
        "```\n",
        "\n",
        "This chunks of functions executes the following procedure.\n",
        "\n",
        "Step 1   Remove duplication of words\n",
        "\n",
        "Step 2   Convert upper case to lower case\n",
        "\n",
        "Step 3   Sort the list of words\n",
        "\n",
        "Result   Duplicated words are present in the 'text1_b' list because semantically same words with a difference on capitalization is regarded as different words and then they are converted into words only with lower cases.\n",
        "\n",
        "In the end, we obtain duplicated words, for example, two 'apple', where the result is probably not intended by a user."
      ],
      "metadata": {
        "id": "y6HFEKAd0NFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1_b = sorted(w.lower() for w in set(text1))\n",
        "\n",
        "# Check if there is duplicated words in the text1_b\n",
        "# If that's the case, the output of line 3 is larger than the one of line 4. \n",
        "print(len(text1_b))       # line 3\n",
        "print(len(set(text1_b)))  # line 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUZVy_hXv50d",
        "outputId": "fb1f4f4c-45e5-4734-850e-7620027df711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19317\n",
            "17231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which one will give a larger value?\n",
        "\n",
        "The latter, \"sorted(w.lower() for w in set(text1))\", gives a larger value regarding the number of words contained after the processes.\n",
        "\n",
        "Will this be the case for other texts?\n",
        "\n",
        "Yes, this will be the case for other texts.\n",
        "The former code gets rid of duplication of words.\n",
        "The latter code cannot eliminates the number of semantically same words that comes with a differences on capitalization."
      ],
      "metadata": {
        "id": "EPd1RcAVqFB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Find all the four-letter words in the Chat Corpus (text5)\n",
        "\n",
        "With the help of a frequency distribution (FreqDist), show these words in decreasing order of frequency."
      ],
      "metadata": {
        "id": "rn18e9JaRwAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a frequency list from text5 \n",
        "fdist5 = FreqDist(text5)\n",
        "\n",
        "def freq(word):\n",
        "  return fdist5[word]\n",
        "\n",
        "four_letter_list = sorted((w for w in set(text5) if len(w) == 4), key = freq, reverse=True)\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Print all the four-letter words in descending order ragarding frequency.\n",
        "for w, i in zip(four_letter_list, np.arange(1, len(four_letter_list))):\n",
        "  print(\"| %s freq: %d \" % (w, fdist5[w]), end='')\n",
        "  if i % 7 == 0:\n",
        "    print('|')\n",
        "\n",
        "#for w in four_letter_list:\n",
        "#  print(\"Word:  %s  Freq: %d\" % (w, fdist5[w]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmNnKxyVRweI",
        "outputId": "fd7e33ae-1278-4e45-91ff-5e381b4a6482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| JOIN freq: 1021 | PART freq: 1016 | that freq: 274 | what freq: 183 | here freq: 181 | .... freq: 170 | have freq: 164 |\n",
            "| like freq: 156 | with freq: 152 | chat freq: 142 | your freq: 137 | good freq: 130 | just freq: 125 | lmao freq: 107 |\n",
            "| know freq: 103 | room freq: 98 | from freq: 92 | this freq: 86 | well freq: 81 | hiya freq: 78 | back freq: 78 |\n",
            "| they freq: 77 | yeah freq: 75 | dont freq: 75 | want freq: 71 | love freq: 60 | guys freq: 58 | some freq: 58 |\n",
            "| been freq: 57 | talk freq: 56 | nice freq: 52 | time freq: 50 | when freq: 48 | haha freq: 44 | make freq: 44 |\n",
            "| need freq: 43 | girl freq: 43 | U122 freq: 42 | MODE freq: 41 | much freq: 40 | will freq: 40 | then freq: 40 |\n",
            "| over freq: 39 | work freq: 38 | were freq: 38 | take freq: 37 | U115 freq: 36 | U121 freq: 36 | song freq: 36 |\n",
            "| U105 freq: 35 | does freq: 35 | U156 freq: 35 | even freq: 35 | seen freq: 35 | damn freq: 34 | more freq: 34 |\n",
            "| come freq: 33 | only freq: 33 | hell freq: 29 | them freq: 28 | long freq: 28 | name freq: 27 | tell freq: 27 |\n",
            "| baby freq: 26 | away freq: 26 | look freq: 26 | sure freq: 26 | call freq: 26 | U114 freq: 25 | U110 freq: 25 |\n",
            "| play freq: 25 | cool freq: 24 | down freq: 24 | NICK freq: 24 | sexy freq: 23 | said freq: 23 | many freq: 23 |\n",
            "| hate freq: 23 | ever freq: 22 | last freq: 22 | hear freq: 21 | life freq: 21 | live freq: 20 | same freq: 19 |\n",
            "| LMAO freq: 19 | very freq: 19 | give freq: 19 | stop freq: 19 | must freq: 19 | mean freq: 19 | feel freq: 19 |\n",
            "| cant freq: 18 | What freq: 18 | hugs freq: 18 | find freq: 18 | !!!! freq: 18 | shit freq: 17 | ???? freq: 17 |\n",
            "| hair freq: 17 | left freq: 17 | busy freq: 17 | U104 freq: 17 | nite freq: 17 | lost freq: 17 | game freq: 16 |\n",
            "| real freq: 16 | fine freq: 16 | lets freq: 15 | fuck freq: 15 | sits freq: 15 | eyes freq: 15 | heya freq: 15 |\n",
            "| kill freq: 15 | true freq: 14 | shut freq: 14 | wait freq: 14 | goes freq: 14 | read freq: 14 | keep freq: 14 |\n",
            "| pick freq: 13 | U168 freq: 13 | near freq: 13 | nope freq: 13 | else freq: 13 | free freq: 13 | bout freq: 12 |\n",
            "| U102 freq: 12 | stay freq: 12 | awww freq: 12 | This freq: 12 | used freq: 12 | cold freq: 12 | gets freq: 12 |\n",
            "| head freq: 12 | than freq: 12 | hope freq: 12 | hehe freq: 12 | male freq: 12 | told freq: 12 | U107 freq: 11 |\n",
            "| face freq: 11 | doin freq: 11 | yall freq: 11 | wont freq: 11 | .. . freq: 11 | year freq: 11 | U119 freq: 11 |\n",
            "| perv freq: 11 | kids freq: 11 | home freq: 11 | into freq: 11 | babe freq: 11 | hard freq: 10 | U132 freq: 10 |\n",
            "| Liam freq: 10 | week freq: 10 | show freq: 10 | mind freq: 10 | Yeah freq: 10 | U101 freq: 10 | Well freq: 10 |\n",
            "| once freq: 10 | help freq: 10 | type freq: 9 | hour freq: 9 | care freq: 9 | ; .. freq: 9 | soon freq: 9 |\n",
            "| mine freq: 9 | sick freq: 9 | best freq: 9 | kiss freq: 9 | such freq: 9 | nick freq: 9 | hmmm freq: 9 |\n",
            "| rock freq: 9 | book freq: 9 | pics freq: 9 | crap freq: 9 | dead freq: 9 | aint freq: 9 | runs freq: 9 |\n",
            "| full freq: 9 | dang freq: 9 | neck freq: 9 | days freq: 9 | blue freq: 8 | suck freq: 8 | says freq: 8 |\n",
            "| lady freq: 8 | case freq: 8 | hows freq: 8 | wife freq: 8 | wana freq: 8 | heyy freq: 8 | sang freq: 8 |\n",
            "| U139 freq: 8 | went freq: 8 | U144 freq: 8 | word freq: 8 | made freq: 8 | U169 freq: 7 | wear freq: 7 |\n",
            "| okay freq: 7 | dear freq: 7 | ahhh freq: 7 | rule freq: 7 | Hiya freq: 7 | dude freq: 7 | alot freq: 7 |\n",
            "| U108 freq: 7 | took freq: 7 | kick freq: 7 | hand freq: 7 | fast freq: 7 | That freq: 7 | next freq: 6 |\n",
            "| <--- freq: 6 | U165 freq: 6 | ride freq: 6 | U142 freq: 6 | gone freq: 6 | seem freq: 6 | pink freq: 6 |\n",
            "| Last freq: 6 | U197 freq: 6 | U120 freq: 6 | They freq: 6 | part freq: 6 | sing freq: 6 | oops freq: 6 |\n",
            "| ball freq: 6 | food freq: 6 | U129 freq: 6 | done freq: 6 | knew freq: 6 | list freq: 6 | comp freq: 6 |\n",
            "| poor freq: 6 | main freq: 6 | most freq: 6 | Song freq: 6 | U116 freq: 6 | send freq: 6 | whos freq: 6 |\n",
            "| U520 freq: 6 | thru freq: 6 | goin freq: 6 | sock freq: 6 | U103 freq: 6 | )))) freq: 6 | blah freq: 6 |\n",
            "| till freq: 5 | fire freq: 5 | late freq: 5 | wall freq: 5 | idea freq: 5 | lick freq: 5 | Have freq: 5 |\n",
            "| When freq: 5 | xbox freq: 5 | lose freq: 5 | nose freq: 5 | felt freq: 5 | feet freq: 5 | caps freq: 5 |\n",
            "| boys freq: 5 | fall freq: 5 | cali freq: 5 | kool freq: 5 | roll freq: 5 | both freq: 5 | fool freq: 5 |\n",
            "| ohhh freq: 5 | hang freq: 5 | miss freq: 5 | U128 freq: 5 | joke freq: 5 | came freq: 5 | warm freq: 5 |\n",
            "| beer freq: 5 | heck freq: 5 | also freq: 5 | legs freq: 5 | boss freq: 5 | #### freq: 5 | meds freq: 5 |\n",
            "| land freq: 5 | wish freq: 5 | meet freq: 5 | soul freq: 5 | luck freq: 5 | yoko freq: 5 | easy freq: 5 |\n",
            "| Lime freq: 5 | beat freq: 4 | huge freq: 4 | open freq: 4 | evil freq: 4 | each freq: 4 | grrr freq: 4 |\n",
            "| turn freq: 4 | pain freq: 4 | ROOM freq: 4 | Like freq: 4 | U133 freq: 4 | rest freq: 4 | U989 freq: 4 |\n",
            "| U126 freq: 4 | U988 freq: 4 | lame freq: 4 | quit freq: 4 | puff freq: 4 | ouch freq: 4 | U820 freq: 4 |\n",
            "| sigh freq: 4 | U130 freq: 4 | U117 freq: 4 | jerk freq: 4 | line freq: 4 | ugly freq: 4 | shes freq: 4 |\n",
            "| glad freq: 4 | U146 freq: 4 | door freq: 4 | none freq: 4 | cute freq: 4 | U154 freq: 4 | kent freq: 4 |\n",
            "| fart freq: 4 | ,,,, freq: 4 | U123 freq: 4 | ones freq: 4 | high freq: 4 | lord freq: 4 | U219 freq: 4 |\n",
            "| ways freq: 4 | woot freq: 4 | pfft freq: 4 | U819 freq: 4 | U196 freq: 4 | holy freq: 4 | shot freq: 4 |\n",
            "| mmmm freq: 4 | date freq: 4 | hook freq: 4 | team freq: 4 | self freq: 4 | pass freq: 4 | ummm freq: 4 |\n",
            "| wazz freq: 3 | walk freq: 3 | butt freq: 3 | elle freq: 3 | jump freq: 3 | bend freq: 3 | toes freq: 3 |\n",
            "| U141 freq: 3 | U148 freq: 3 | move freq: 3 | slow freq: 3 | Your freq: 3 | gold freq: 3 | toss freq: 3 |\n",
            "| vote freq: 3 | Same freq: 3 | hiii freq: 3 | mary freq: 3 | THAT freq: 3 | hola freq: 3 | U145 freq: 3 |\n",
            "| rain freq: 3 | piff freq: 3 | bare freq: 3 | slap freq: 3 | hank freq: 3 | amen freq: 3 | U153 freq: 3 |\n",
            "| ahem freq: 3 | snow freq: 3 | 2006 freq: 3 | rubs freq: 3 | army freq: 3 | died freq: 3 | hawt freq: 3 |\n",
            "| U109 freq: 3 | CHAT freq: 3 | yawn freq: 3 | guyz freq: 3 | wack freq: 3 | orgy freq: 3 | roof freq: 3 |\n",
            "| yada freq: 3 | road freq: 3 | band freq: 3 | (((( freq: 3 | hail freq: 3 | lead freq: 3 | wash freq: 3 |\n",
            "| Elev freq: 3 | U106 freq: 3 | hurt freq: 3 | itch freq: 3 | U136 freq: 3 | clap freq: 3 | imma freq: 3 |\n",
            "| town freq: 3 | gawd freq: 3 | deal freq: 3 | DING freq: 3 | swim freq: 3 | ring freq: 3 | hick freq: 3 |\n",
            "| U163 freq: 3 | wine freq: 3 | deop freq: 3 | Only freq: 3 | ello freq: 3 | hump freq: 3 | note freq: 3 |\n",
            "| tune freq: 3 | isnt freq: 3 | Wind freq: 3 | nana freq: 3 | skin freq: 3 | soft freq: 3 | half freq: 3 |\n",
            "| AKDT freq: 3 | babi freq: 2 | kind freq: 2 | ages freq: 2 | sore freq: 2 | ohio freq: 2 | ?!?! freq: 2 |\n",
            "| ltns freq: 2 | mama freq: 2 | NONE freq: 2 | lies freq: 2 | yeas freq: 2 | born freq: 2 | lawl freq: 2 |\n",
            "| deaf freq: 2 | Here freq: 2 | Tisk freq: 2 | city freq: 2 | eats freq: 2 | adds freq: 2 | hall freq: 2 |\n",
            "| fits freq: 2 | mins freq: 2 | park freq: 2 | FROM freq: 2 | sell freq: 2 | cmon freq: 2 | whoa freq: 2 |\n",
            "| whud freq: 2 | ciao freq: 2 | five freq: 2 | >:-> freq: 2 | burp freq: 2 | John freq: 2 | DONT freq: 2 |\n",
            "| golf freq: 2 | eric freq: 2 | bite freq: 2 | temp freq: 2 | corn freq: 2 | humm freq: 2 | rich freq: 2 |\n",
            "| twin freq: 2 | moon freq: 2 | U172 freq: 2 | Love freq: 2 | gays freq: 2 | mike freq: 2 | spot freq: 2 |\n",
            "| <<<< freq: 2 | HAVE freq: 2 | <333 freq: 2 | howz freq: 2 | john freq: 2 | cost freq: 2 | Ohio freq: 2 |\n",
            "| U138 freq: 2 | pies freq: 2 | U100 freq: 2 | DOES freq: 2 | gimp freq: 2 | High freq: 2 | Lets freq: 2 |\n",
            "| yard freq: 2 | Gosh freq: 2 | bear freq: 2 | KoOL freq: 2 | cell freq: 2 | zone freq: 2 | ewww freq: 2 |\n",
            "| tock freq: 2 | root freq: 2 | argh freq: 2 | opps freq: 2 | U175 freq: 2 | uses freq: 2 | porn freq: 2 |\n",
            "| meat freq: 2 | YOUR freq: 2 | 1996 freq: 2 | rent freq: 2 | deep freq: 2 | hott freq: 2 | Tell freq: 2 |\n",
            "| chip freq: 2 | cash freq: 2 | Nice freq: 2 | drew freq: 2 | U112 freq: 2 | hmph freq: 2 | Just freq: 2 |\n",
            "| WITH freq: 2 | spin freq: 2 | flaw freq: 2 | typo freq: 2 | Days freq: 2 | hold freq: 2 | STOP freq: 2 |\n",
            "| heal freq: 2 | hits freq: 2 | Sure freq: 2 | sand freq: 2 | Stop freq: 2 | newp freq: 2 | O.k. freq: 2 |\n",
            "| Lmao freq: 2 | sort freq: 2 | clue freq: 2 | shop freq: 2 | tyvm freq: 2 | n9ne freq: 2 | trip freq: 2 |\n",
            "| flow freq: 2 | U155 freq: 2 | Lies freq: 2 | ??!! freq: 2 | Ahhh freq: 2 | haze freq: 2 | past freq: 2 |\n",
            "| sooo freq: 2 | whip freq: 2 | side freq: 2 | foot freq: 2 | Down freq: 2 | mass freq: 2 | U170 freq: 2 |\n",
            "| Okay freq: 2 | ex's freq: 2 | Drew freq: 2 | any1 freq: 2 | limp freq: 2 | aunt freq: 2 | hint freq: 2 |\n",
            "| Dang freq: 2 | luvs freq: 2 | blew freq: 2 | Poor freq: 2 | ears freq: 2 | cars freq: 2 | wOOt freq: 2 |\n",
            "| kewl freq: 2 | wooo freq: 2 | dumb freq: 2 | U111 freq: 2 | doll freq: 2 | tick freq: 2 | From freq: 2 |\n",
            "| Come freq: 2 | plan freq: 2 | drop freq: 2 | Cool freq: 2 | rofl freq: 2 | area freq: 2 | Live freq: 2 |\n",
            "| wats freq: 2 | Ummm freq: 2 | Heyy freq: 2 | grrl freq: 2 | pool freq: 2 | tisk freq: 2 | club freq: 2 |\n",
            "| U190 freq: 2 | cast freq: 2 | !!!. freq: 2 | phil freq: 2 | tail freq: 1 | whys freq: 1 | Male freq: 1 |\n",
            "| Swim freq: 1 | U113 freq: 1 | sent freq: 1 | caca freq: 1 | Heya freq: 1 | ladz freq: 1 | dawg freq: 1 |\n",
            "| Paul freq: 1 | HUGE freq: 1 | hill freq: 1 | KNOW freq: 1 | out. freq: 1 | yout freq: 1 | pull freq: 1 |\n",
            "| lisa freq: 1 | OOPS freq: 1 | kong freq: 1 | mena freq: 1 | mahn freq: 1 | poem freq: 1 | ebay freq: 1 |\n",
            "| hogs freq: 1 | Tina freq: 1 | U150 freq: 1 | mang freq: 1 | dies freq: 1 | Phil freq: 1 | thot freq: 1 |\n",
            "| febe freq: 1 | 9:10 freq: 1 | duet freq: 1 | Even freq: 1 | U149 freq: 1 | akon freq: 1 | sean freq: 1 |\n",
            "| WHEN freq: 1 | tend freq: 1 | VBox freq: 1 | vega freq: 1 | York freq: 1 | grea freq: 1 | syck freq: 1 |\n",
            "| poof freq: 1 | 7:45 freq: 1 | HALO freq: 1 | enuf freq: 1 | LONG freq: 1 | chit freq: 1 | Jane freq: 1 |\n",
            "| Holy freq: 1 | <~~~ freq: 1 | spit freq: 1 | anti freq: 1 | bois freq: 1 | gees freq: 1 | hooo freq: 1 |\n",
            "| toop freq: 1 | size freq: 1 | arms freq: 1 | COME freq: 1 | saME freq: 1 | scum freq: 1 | kmph freq: 1 |\n",
            "| lazy freq: 1 | bugs freq: 1 | west freq: 1 | jack freq: 1 | wide freq: 1 | bell freq: 1 | fock freq: 1 |\n",
            "| boom freq: 1 | byes freq: 1 | bacl freq: 1 | tall freq: 1 | fish freq: 1 | Been freq: 1 | toke freq: 1 |\n",
            "| star freq: 1 | Awww freq: 1 | mark freq: 1 | Ctrl freq: 1 | WILL freq: 1 | Came freq: 1 | Show freq: 1 |\n",
            "| 1.98 freq: 1 | Were freq: 1 | dirt freq: 1 | thje freq: 1 | Lion freq: 1 | Look freq: 1 | HOTT freq: 1 |\n",
            "| U542 freq: 1 | Rick freq: 1 | samn freq: 1 | Dood freq: 1 | Nooo freq: 1 | junk freq: 1 | Kiss freq: 1 |\n",
            "| rose freq: 1 | Chat freq: 1 | Eggs freq: 1 | brat freq: 1 | jeep freq: 1 | boot freq: 1 | four freq: 1 |\n",
            "| ogan freq: 1 | woof freq: 1 | NTMN freq: 1 | 6:51 freq: 1 | Fort freq: 1 | sink freq: 1 | orta freq: 1 |\n",
            "| twit freq: 1 | AWAY freq: 1 | FACE freq: 1 | quiz freq: 1 | kold freq: 1 | nuff freq: 1 | ther freq: 1 |\n",
            "| tenn freq: 1 | U137 freq: 1 | Take freq: 1 | hurr freq: 1 | hide freq: 1 | sexi freq: 1 | aime freq: 1 |\n",
            "| daft freq: 1 | 39.3 freq: 1 | Ruth freq: 1 | MUAH freq: 1 | sori freq: 1 | Life freq: 1 | nods freq: 1 |\n",
            "| gret freq: 1 | 18ST freq: 1 | gear freq: 1 | Hail freq: 1 | pwns freq: 1 | mite freq: 1 | mess freq: 1 |\n",
            "| grew freq: 1 | choc freq: 1 | Bone freq: 1 | SExy freq: 1 | o.k. freq: 1 | nawt freq: 1 | Slip freq: 1 |\n",
            "| card freq: 1 | pray freq: 1 | test freq: 1 | 1900 freq: 1 | ahah freq: 1 | outs freq: 1 | Kold freq: 1 |\n",
            "| waaa freq: 1 | Girl freq: 1 | form freq: 1 | keys freq: 1 | Iowa freq: 1 | lala freq: 1 | cums freq: 1 |\n",
            "| caan freq: 1 | noth freq: 1 | frst freq: 1 | cyas freq: 1 | herE freq: 1 | tart freq: 1 | tits freq: 1 |\n",
            "| King freq: 1 | Kent freq: 1 | Talk freq: 1 | 10th freq: 1 | este freq: 1 | addy freq: 1 | cook freq: 1 |\n",
            "| sexs freq: 1 | idnt freq: 1 | post freq: 1 | plow freq: 1 | moms freq: 1 | Werd freq: 1 | asss freq: 1 |\n",
            "| eeww freq: 1 | Teck freq: 1 | 4:03 freq: 1 | Road freq: 1 | pair freq: 1 | asks freq: 1 | RN's freq: 1 |\n",
            "| sum1 freq: 1 | dick freq: 1 | GOOD freq: 1 | surf freq: 1 | pimp freq: 1 | fake freq: 1 | ROFL freq: 1 |\n",
            "| uyes freq: 1 | jush freq: 1 | whew freq: 1 | sayn freq: 1 | buff freq: 1 | pope freq: 1 | nude freq: 1 |\n",
            "| wean freq: 1 | PMSL freq: 1 | Very freq: 1 | lake freq: 1 | Long freq: 1 | Uhhh freq: 1 | loss freq: 1 |\n",
            "| hong freq: 1 | lyin freq: 1 | 98.6 freq: 1 | peel freq: 1 | Fade freq: 1 | lust freq: 1 | Type freq: 1 |\n",
            "| !... freq: 1 | :o * freq: 1 | ques freq: 1 | cuss freq: 1 | Yoko freq: 1 | thah freq: 1 | Rock freq: 1 |\n",
            "| benz freq: 1 | Joey freq: 1 | it's freq: 1 | yell freq: 1 | brwn freq: 1 | Kids freq: 1 | nads freq: 1 |\n",
            "| yesh freq: 1 | DAMN freq: 1 | loud freq: 1 | outa freq: 1 | Chop freq: 1 | U143 freq: 1 | inch freq: 1 |\n",
            "| z-ro freq: 1 | Hott freq: 1 | cops freq: 1 | Food freq: 1 | whou freq: 1 | thnx freq: 1 | hiom freq: 1 |\n",
            "| Sexy freq: 1 | boed freq: 1 | Save freq: 1 | evah freq: 1 | TYPR freq: 1 | U181 freq: 1 | Prof freq: 1 |\n",
            "| Help freq: 1 | poop freq: 1 | urls freq: 1 | Haha freq: 1 | dust freq: 1 | prep freq: 1 | pork freq: 1 |\n",
            "| barn freq: 1 | ghet freq: 1 | seth freq: 1 | oooh freq: 1 | peek freq: 1 | sets freq: 1 | giva freq: 1 |\n",
            "| gags freq: 1 | wild freq: 1 | offa freq: 1 | guts freq: 1 | draw freq: 1 | puke freq: 1 | 1.99 freq: 1 |\n",
            "| term freq: 1 | Home freq: 1 | Lord freq: 1 | gray freq: 1 | wood freq: 1 | east freq: 1 | prob freq: 1 |\n",
            "| sext freq: 1 | waht freq: 1 | Turn freq: 1 | wher freq: 1 | bomb freq: 1 | Hill freq: 1 | 2Pac freq: 1 |\n",
            "| crop freq: 1 | SIZE freq: 1 | <3's freq: 1 | U147 freq: 1 | Hugs freq: 1 | PM's freq: 1 | vamp freq: 1 |\n",
            "| wins freq: 1 | pigs freq: 1 | Hold freq: 1 | worl freq: 1 | kina freq: 1 | tape freq: 1 | king freq: 1 |\n",
            "| Troy freq: 1 | 3:45 freq: 1 | tory freq: 1 | pasa freq: 1 | abou freq: 1 | EVEN freq: 1 | Cute freq: 1 |\n",
            "| weed freq: 1 | bowl freq: 1 | xmas freq: 1 | sips freq: 1 | Sat. freq: 1 | None freq: 1 | LoVe freq: 1 |\n",
            "| cams freq: 1 | mkay freq: 1 | lois freq: 1 | grin freq: 1 | push freq: 1 | Mine freq: 1 | fawk freq: 1 |\n",
            "| haaa freq: 1 | tthe freq: 1 | yoll freq: 1 | http freq: 1 | Dawn freq: 1 | lool freq: 1 | Pour freq: 1 |\n",
            "| exit freq: 1 | dump freq: 1 | mode freq: 1 | bloe freq: 1 | 9.53 freq: 1 | dint freq: 1 | wore freq: 1 |\n",
            "| heat freq: 1 | spat freq: 1 | FINE freq: 1 | Eyes freq: 1 | smax freq: 1 | 1299 freq: 1 | ribs freq: 1 |\n",
            "| vent freq: 1 | Tide freq: 1 | 6:41 freq: 1 | U118 freq: 1 | gift freq: 1 | Ohhh freq: 1 | soup freq: 1 |\n",
            "| jeff freq: 1 | rang freq: 1 | Born freq: 1 | Kick freq: 1 | howl freq: 1 | Wyte freq: 1 | tooo freq: 1 |\n",
            "| NAME freq: 1 | 1cos freq: 1 | yes. freq: 1 | rape freq: 1 | wire freq: 1 | Hero freq: 1 | 1985 freq: 1 |\n",
            "| body freq: 1 | serg freq: 1 | eeek freq: 1 | nerd freq: 1 | Over freq: 1 | lots freq: 1 | otay freq: 1 |\n",
            "| chik freq: 1 | HERE freq: 1 | pour freq: 1 | fair freq: 1 | yess freq: 1 | MRIs freq: 1 | pure freq: 1 |\n",
            "| SSRI freq: 1 | okey freq: 1 | soda freq: 1 | drug freq: 1 | dotn freq: 1 | dogs freq: 1 | Tiff freq: 1 |\n",
            "| seat freq: 1 | woah freq: 1 | HAHA freq: 1 | mono freq: 1 | VVil freq: 1 | hgey freq: 1 | Good freq: 1 |\n",
            "| Rofl freq: 1 | slam freq: 1 | ltnc freq: 1 | ruff freq: 1 | Rule freq: 1 | mauh freq: 1 | tjhe freq: 1 |\n",
            "| jude freq: 1 | Dude freq: 1 | cure freq: 1 | mofo freq: 1 | coat freq: 1 | 1980 freq: 1 | Seee freq: 1 |\n",
            "| LIVE freq: 1 | Away freq: 1 | allo freq: 1 | ok'd freq: 1 | teck freq: 1 | GrlZ freq: 1 | SOME freq: 1 |\n",
            "| 1930 freq: 1 | whoo freq: 1 | Mary freq: 1 | crib freq: 1 | geez freq: 1 | dork freq: 1 | t he freq: 1 |\n",
            "| wind freq: 1 | Judy freq: 1 | AKST freq: 1 | poot freq: 1 | THEY freq: 1 | bust freq: 1 | wubs freq: 1 |\n",
            "| Heys freq: 1 | tips freq: 1 | lube freq: 1 | Reub freq: 1 | mame freq: 1 | bong freq: 1 | ELSE freq: 1 |\n",
            "| beam freq: 1 | Nova freq: 1 | LOUD freq: 1 | site freq: 1 | bein freq: 1 | base freq: 1 | pm'n freq: 1 |\n",
            "| bike freq: 1 | knee freq: 1 | paid freq: 1 | safe freq: 1 | GIRL freq: 1 | shup freq: 1 | Damn freq: 1 |\n",
            "| 6:53 freq: 1 | hots freq: 1 | tere freq: 1 | brad freq: 1 | bull freq: 1 | plus freq: 1 | 1200 freq: 1 |\n",
            "| CAPS freq: 1 | herd freq: 1 | WHOA freq: 1 | Boyz freq: 1 | City freq: 1 | Elle freq: 1 | rats freq: 1 |\n",
            "| feat freq: 1 | 64.8 freq: 1 | GUYS freq: 1 | disc freq: 1 | perk freq: 1 | 6:38 freq: 1 | tlak freq: 1 |\n",
            "| givs freq: 1 | TIME freq: 1 | bred freq: 1 | span freq: 1 | 45.5 freq: 1 | SEEN freq: 1 | slip freq: 1 |\n",
            "| Does freq: 1 | firs freq: 1 | bone freq: 1 | calm freq: 1 | Hand freq: 1 | U134 freq: 1 | Time freq: 1 |\n",
            "| Deep freq: 1 | wrap freq: 1 | sign freq: 1 | !??? freq: 1 | wuts freq: 1 | ally freq: 1 | able freq: 1 |\n",
            "| hawT freq: 1 | Rush freq: 1 | gooo freq: 1 | cepn freq: 1 | page freq: 1 | CALI freq: 1 | gosh freq: 1 |\n",
            "| lapd freq: 1 | 2:55 freq: 1 | Oops freq: 1 | Evil freq: 1 | goof freq: 1 | U158 freq: 1 | acid freq: 1 |\n",
            "| 100% freq: 1 | West freq: 1 | Then freq: 1 | cock freq: 1 | Drop freq: 1 | MORE freq: 1 | dark freq: 1 |\n",
            "| jail freq: 1 | ussy freq: 1 | YALL freq: 1 | Maps freq: 1 | wrek freq: 1 | 4.20 freq: 1 | Kewl freq: 1 |\n",
            "| TEXT freq: 1 | nada freq: 1 | yw's freq: 1 | puts freq: 1 | Room freq: 1 | News freq: 1 | lung freq: 1 |\n",
            "| tiff freq: 1 | guns freq: 1 | clay freq: 1 | seee freq: 1 | Will freq: 1 | lol. freq: 1 | dyed freq: 1 |\n",
            "| QUIT freq: 1 | mami freq: 1 | nawp freq: 1 | 98.5 freq: 1 | ooer freq: 1 | TALK freq: 1 | ohwa freq: 1 |\n",
            "| icky freq: 1 | Need freq: 1 | Jess freq: 1 | Rang freq: 1 | anal freq: 1 | heee freq: 1 | 2DAY freq: 1 |\n",
            "| JUST freq: 1 | pmsl freq: 1 | menu freq: 1 | Back freq: 1 | fear freq: 1 | Meep freq: 1 | raed freq: 1 |\n",
            "| halo freq: 1 | Nope freq: 1 | LAst freq: 1 | gals freq: 1 | poll freq: 1 | U164 freq: 1 | coem freq: 1 |\n",
            "| Mono freq: 1 | salt freq: 1 | Hard freq: 1 | blow freq: 1 | numb freq: 1 | bird freq: 1 | pm's freq: 1 |\n",
            "| kept freq: 1 | hazy freq: 1 | ssid freq: 1 | Matt freq: 1 | dojn freq: 1 | bied freq: 1 | \"... freq: 1 |\n",
            "| Care freq: 1 | scar freq: 1 | LATE freq: 1 | yeee freq: 1 | pine freq: 1 | owww freq: 1 | laid freq: 1 |\n",
            "| rush freq: 1 | scuk freq: 1 | .op. freq: 1 | dman freq: 1 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Use the corpus module to explore auten-persuasion.text.\n",
        "How many words tokens does this book have? How many word types (set())?"
      ],
      "metadata": {
        "id": "ZZrzOxOOlvEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "print(\"The number of tokes in 'austen-persuasion.txt': \" + str(len(gutenberg.words(\"austen-persuasion.txt\")))) \n",
        "print(\"The number of types in 'austen-persuasion.txt': \" + str(len(set(w.lower() for w in gutenberg.words(\"austen-persuasion.txt\")))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOlQLe5MmPuX",
        "outputId": "3c5d51a1-90e6-495e-822a-ff357e70660e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of tokes in 'austen-persuasion.txt': 98171\n",
            "The number of types in 'austen-persuasion.txt': 5835\n"
          ]
        }
      ]
    }
  ]
}